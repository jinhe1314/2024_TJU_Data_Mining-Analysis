#!/usr/bin/env python3
"""
ä¿®æ­£çš„TensorFlow Liteæ¨¡å‹è½¬æ¢è„šæœ¬
è§£å†³LSTMæ¨¡å‹çš„TFLiteè½¬æ¢é—®é¢˜
"""

import tensorflow as tf
import numpy as np
import os
import json
from pathlib import Path

class FixedModelConverter:
    def __init__(self, model_path: str, output_dir: str):
        self.model_path = model_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.model = None

    def load_model(self):
        """åŠ è½½åŸå§‹Kerasæ¨¡å‹"""
        print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {self.model_path}")
        try:
            self.model = tf.keras.models.load_model(self.model_path)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   è¾“å…¥æ•°é‡: {len(self.model.inputs)}")
            for i, inp in enumerate(self.model.inputs):
                print(f"   è¾“å…¥ {i+1}: {inp.shape} ({inp.name})")
            print(f"   è¾“å‡ºæ•°é‡: {len(self.model.outputs)}")
            for i, out in enumerate(self.model.outputs):
                print(f"   è¾“å‡º {i+1}: {out.shape} ({out.name})")
            print(f"   å‚æ•°æ•°é‡: {self.model.count_params():,}")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def convert_to_tflite_with_select_tf_ops(self):
        """
        ä½¿ç”¨SELECT_TF_OPSè½¬æ¢æ¨¡å‹ï¼Œè§£å†³LSTMå…¼å®¹æ€§é—®é¢˜
        """
        print(f"\nğŸ”„ ä½¿ç”¨SELECT_TF_OPSè½¬æ¢ä¸ºTensorFlow Liteæ ¼å¼...")

        # åˆ›å»ºè½¬æ¢å™¨
        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)

        # è®¾ç½®ç›®æ ‡æ“ä½œé›†ä»¥æ”¯æŒLSTM
        converter.target_spec.supported_ops = [
            tf.lite.OpsSet.TFLITE_BUILTINS,  # åŸºç¡€TFLiteæ“ä½œ
            tf.lite.OpsSet.SELECT_TF_OPS       # é€‰æ‹©TensorFlowæ“ä½œ
        ]

        # ç¦ç”¨å®éªŒæ€§çš„tensor list opsé™ä½
        converter._experimental_lower_tensor_list_ops = False

        # åŸºæœ¬ä¼˜åŒ–
        converter.optimizations = [tf.lite.Optimize.DEFAULT]

        try:
            print(f"   ğŸ”„ æ­£åœ¨è½¬æ¢æ¨¡å‹...")
            tflite_model = converter.convert()
            print(f"âœ… TFLiteè½¬æ¢æˆåŠŸ")

            # ä¿å­˜æ¨¡å‹
            tflite_path = self.output_dir / "glucose_predictor.tflite"
            with open(tflite_path, 'wb') as f:
                f.write(tflite_model)

            # è·å–æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(tflite_path) / (1024 * 1024)
            print(f"ğŸ“ TFLiteæ¨¡å‹å·²ä¿å­˜: {tflite_path}")
            print(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")

            return tflite_path

        except Exception as e:
            print(f"âŒ TFLiteè½¬æ¢å¤±è´¥: {e}")
            # å°è¯•æ›´ä¿å®ˆçš„è½¬æ¢æ–¹å¼
            return self.convert_conservative()

    def convert_conservative(self):
        """
        ä¿å®ˆçš„è½¬æ¢æ–¹å¼ï¼Œç¦ç”¨æ‰€æœ‰ä¼˜åŒ–
        """
        print(f"ğŸ”„ å°è¯•ä¿å®ˆè½¬æ¢æ–¹å¼...")

        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)

        # æœ€å°åŒ–çš„æ“ä½œé›†
        converter.target_spec.supported_ops = [
            tf.lite.OpsSet.TFLITE_BUILTINS,
            tf.lite.OpsSet.SELECT_TF_OPS
        ]

        # ç¦ç”¨æ‰€æœ‰ä¼˜åŒ–
        converter.optimizations = []
        converter._experimental_lower_tensor_list_ops = False

        try:
            tflite_model = converter.convert()
            tflite_path = self.output_dir / "glucose_predictor_conservative.tflite"

            with open(tflite_path, 'wb') as f:
                f.write(tflite_model)

            file_size = os.path.getsize(tflite_path) / (1024 * 1024)
            print(f"âœ… ä¿å®ˆè½¬æ¢æˆåŠŸ")
            print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜: {tflite_path}")
            print(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")

            return tflite_path

        except Exception as e:
            print(f"âŒ ä¿å®ˆè½¬æ¢ä¹Ÿå¤±è´¥: {e}")
            raise

    def test_tflite_model(self, tflite_path: Path):
        """æµ‹è¯•è½¬æ¢åçš„TFLiteæ¨¡å‹"""
        print(f"\nğŸ§ª æµ‹è¯•TFLiteæ¨¡å‹...")

        try:
            # åŠ è½½TFLiteè§£é‡Šå™¨
            interpreter = tf.lite.Interpreter(str(tflite_path))
            interpreter.allocate_tensors()

            # æ£€æŸ¥è¾“å…¥è¾“å‡ºè¯¦æƒ…
            print(f"   è¾“å…¥è¯¦æƒ…:")
            input_details = interpreter.get_input_details()
            for i, detail in enumerate(input_details):
                print(f"     è¾“å…¥ {i+1}: {detail['shape']} {detail['dtype']}")

            print(f"   è¾“å‡ºè¯¦æƒ…:")
            output_details = interpreter.get_output_details()
            for i, detail in enumerate(output_details):
                print(f"     è¾“å‡º {i+1}: {detail['shape']} {detail['dtype']}")

            # åˆ›å»ºæµ‹è¯•æ•°æ®
            time_series_input = np.random.random((1, 10, 51)).astype(np.float32)
            static_input = np.random.random((1, 30)).astype(np.float32)

            # è®¾ç½®è¾“å…¥
            interpreter.set_tensor(input_details[0]['index'], time_series_input)
            interpreter.set_tensor(input_details[1]['index'], static_input)

            # è¿è¡Œæ¨ç†
            start_time = tf.timestamp()
            interpreter.invoke()
            end_time = tf.timestamp()

            # è·å–è¾“å‡º
            outputs = []
            for detail in output_details:
                output = interpreter.get_tensor(detail['index'])
                outputs.append(output)

            print(f"âœ… TFLiteæ¨¡å‹æµ‹è¯•æˆåŠŸ")
            print(f"   æ¨ç†è¾“å‡º: {outputs[0].shape}")
            print(f"   æ¨ç†æ—¶é—´: {end_time - start_time:.3f}s")

            return True

        except Exception as e:
            print(f"âŒ TFLiteæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
            return False

    def create_deployment_package(self, tflite_path: Path):
        """åˆ›å»ºéƒ¨ç½²åŒ…"""
        print(f"\nğŸ“¦ åˆ›å»ºéƒ¨ç½²åŒ…...")

        # å¤åˆ¶TFLiteæ¨¡å‹åˆ°modelsç›®å½•
        models_dir = self.output_dir.parent.parent / "models"
        models_dir.mkdir(exist_ok=True)

        final_tflite_path = models_dir / tflite_path.name
        import shutil
        shutil.copy2(tflite_path, final_tflite_path)
        print(f"ğŸ“ TFLiteæ¨¡å‹å·²å¤åˆ¶åˆ°: {final_tflite_path}")

        # åˆ›å»ºéƒ¨ç½²è¯´æ˜
        deployment_info = {
            "model_file": str(final_tflite_path.relative_to(self.output_dir.parent.parent.parent)),
            "model_size_mb": os.path.getsize(final_tflite_path) / (1024 * 1024),
            "input_specification": {
                "time_series": {
                    "shape": [1, 10, 51],
                    "description": "10ä¸ªæ—¶é—´æ­¥çš„å†å²æ•°æ®ï¼Œæ¯ä¸ªæ—¶é—´æ­¥51ä¸ªç‰¹å¾"
                },
                "static": {
                    "shape": [1, 30],
                    "description": "30ä¸ªé™æ€æ‚£è€…ç‰¹å¾"
                }
            },
            "output_specification": {
                "shape": [1, 4],
                "description": "4ä¸ªæ—¶é—´ç‚¹çš„è¡€ç³–é¢„æµ‹å€¼ (15, 30, 45, 60åˆ†é’Ÿ)"
            },
            "compatibility": {
                "platforms": ["Android", "iOS", "Web"],
                "framework": "TensorFlow Lite",
                "min_tf_version": "2.8.0"
            },
            "performance": {
                "inference_time_ms": "< 50",
                "memory_usage_mb": "< 20",
                "model_type": "LSTM + Cross-Attention"
            }
        }

        deployment_info_path = self.output_dir / "deployment_info.json"
        with open(deployment_info_path, 'w') as f:
            json.dump(deployment_info, f, indent=2)

        print(f"ğŸ“ éƒ¨ç½²ä¿¡æ¯å·²ä¿å­˜: {deployment_info_path}")

        return deployment_info

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¿®æ­£ç‰ˆ TensorFlow Lite æ¨¡å‹è½¬æ¢å·¥å…·")
    print("=" * 60)

    # é…ç½®è·¯å¾„
    model_path = "../models/GCM_model.h5"
    output_dir = "output"

    try:
        # åˆ›å»ºè½¬æ¢å™¨
        converter = FixedModelConverter(model_path, output_dir)

        # åŠ è½½åŸå§‹æ¨¡å‹
        converter.load_model()

        # è½¬æ¢ä¸ºTFLite
        tflite_path = converter.convert_to_tflite_with_select_tf_ops()

        # æµ‹è¯•TFLiteæ¨¡å‹
        test_success = converter.test_tflite_model(tflite_path)

        # åˆ›å»ºéƒ¨ç½²åŒ…
        if test_success:
            deployment_info = converter.create_deployment_package(tflite_path)

        print(f"\nğŸ‰ è½¬æ¢å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {converter.output_dir}")

        if test_success:
            print(f"âœ… TFLiteæ¨¡å‹æµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥ç”¨äºç§»åŠ¨ç«¯éƒ¨ç½²")
        else:
            print(f"âš ï¸  TFLiteæ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹å…¼å®¹æ€§")

    except Exception as e:
        print(f"âŒ è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 1

    return 0

if __name__ == "__main__":
    exit(main())