#!/usr/bin/env python3
"""
ç®€åŒ–çš„TensorFlow Liteæ¨¡å‹æ€§èƒ½æµ‹è¯•è„šæœ¬
ä¸“æ³¨äºæ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡æµ‹è¯•
"""

import tensorflow as tf
import numpy as np
import time
import json
import statistics
from pathlib import Path

class SimpleTFLiteTester:
    def __init__(self, tflite_path: str):
        self.tflite_path = Path(tflite_path)
        self.interpreter = None
        self.input_details = None
        self.output_details = None

    def load_model(self):
        """åŠ è½½TFLiteæ¨¡å‹"""
        print(f"ğŸ“¦ åŠ è½½TFLiteæ¨¡å‹: {self.tflite_path}")
        try:
            self.interpreter = tf.lite.Interpreter(str(self.tflite_path))
            self.interpreter.allocate_tensors()

            self.input_details = self.interpreter.get_input_details()
            self.output_details = self.interpreter.get_output_details()

            print(f"âœ… TFLiteæ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   è¾“å…¥æ•°é‡: {len(self.input_details)}")
            for i, detail in enumerate(self.input_details):
                print(f"     è¾“å…¥ {i+1}: {detail['shape']} ({detail['dtype']})")

            print(f"   è¾“å‡ºæ•°é‡: {len(self.output_details)}")
            for i, detail in enumerate(self.output_details):
                print(f"     è¾“å‡º {i+1}: {detail['shape']} ({detail['dtype']})")

        except Exception as e:
            print(f"âŒ TFLiteæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def test_basic_performance(self, num_runs: int = 1000):
        """æµ‹è¯•åŸºç¡€æ¨ç†æ€§èƒ½"""
        print(f"\\nâš¡ åŸºç¡€æ€§èƒ½æµ‹è¯• ({num_runs} æ¬¡è¿è¡Œ)...")

        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        time_series_input = np.random.random((1, 10, 51)).astype(np.float32)
        static_input = np.random.random((1, 30)).astype(np.float32)

        # è®¾ç½®è¾“å…¥
        self.interpreter.set_tensor(self.input_details[0]['index'], time_series_input)
        self.interpreter.set_tensor(self.input_details[1]['index'], static_input)

        # é¢„çƒ­
        for _ in range(10):
            self.interpreter.invoke()

        # æ€§èƒ½æµ‹è¯•
        inference_times = []
        for i in range(num_runs):
            start_time = time.perf_counter()
            self.interpreter.invoke()
            end_time = time.perf_counter()

            inference_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            inference_times.append(inference_time)

            if (i + 1) % 100 == 0:
                print(f"   è¿›åº¦: {i+1}/{num_runs}")

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_time = statistics.mean(inference_times)
        min_time = min(inference_times)
        max_time = max(inference_times)
        p95_time = np.percentile(inference_times, 95)
        p99_time = np.percentile(inference_times, 99)

        performance_stats = {
            "avg_inference_time_ms": avg_time,
            "min_inference_time_ms": min_time,
            "max_inference_time_ms": max_time,
            "p95_inference_time_ms": p95_time,
            "p99_inference_time_ms": p99_time,
            "total_runs": num_runs,
            "throughput_qps": 1000 / (avg_time / 1000)
        }

        print(f"\\nğŸ“Š æ¨ç†æ€§èƒ½ç»Ÿè®¡:")
        print(f"   å¹³å‡æ—¶é—´: {avg_time:.2f} ms")
        print(f"   æœ€å¿«æ—¶é—´: {min_time:.2f} ms")
        print(f"   æœ€æ…¢æ—¶é—´: {max_time:.2f} ms")
        print(f"   P95æ—¶é—´: {p95_time:.2f} ms")
        print(f"   P99æ—¶é—´: {p99_time:.2f} ms")
        print(f"   ååé‡: {performance_stats['throughput_qps']:.1f} QPS")

        return performance_stats

    def test_accuracy_consistency(self, num_tests: int = 100):
        """æµ‹è¯•è¾“å‡ºä¸€è‡´æ€§"""
        print(f"\\nğŸ¯ æµ‹è¯•è¾“å‡ºä¸€è‡´æ€§ ({num_tests} æ¬¡æµ‹è¯•)...")

        outputs = []
        for i in range(num_tests):
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            time_series_input = np.random.random((1, 10, 51)).astype(np.float32)
            static_input = np.random.random((1, 30)).astype(np.float32)

            # è®¾ç½®è¾“å…¥å¹¶è¿è¡Œ
            self.interpreter.set_tensor(self.input_details[0]['index'], time_series_input)
            self.interpreter.set_tensor(self.input_details[1]['index'], static_input)
            self.interpreter.invoke()

            # è·å–è¾“å‡º
            output = self.interpreter.get_tensor(self.output_details[0]['index'])
            outputs.append(output.copy())

        # æ£€æŸ¥è¾“å‡ºä¸€è‡´æ€§
        outputs_array = np.array(outputs)
        mean_output = np.mean(outputs_array, axis=0)
        std_output = np.std(outputs_array, axis=0)

        consistency_stats = {
            "num_tests": num_tests,
            "mean_prediction": mean_output.tolist(),
            "std_deviation": std_output.tolist(),
            "max_deviation": float(np.max(np.std(outputs_array, axis=0))),
            "prediction_range": (float(np.min(outputs_array)), float(np.max(outputs_array)))
        }

        print(f"   å¹³å‡é¢„æµ‹: {mean_output}")
        print(f"   æ ‡å‡†å·®: {std_output}")
        print(f"   æœ€å¤§åå·®: {np.max(np.std(outputs_array, axis=0)):.6f}")

        return consistency_stats

    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        print(f"\\nğŸ“‹ æ¨¡å‹ä¿¡æ¯:")

        model_stats = {
            "file_size_mb": self.tflite_path.stat().st_size / (1024 * 1024),
            "input_shapes": [detail['shape'].tolist() for detail in self.input_details],
            "output_shapes": [detail['shape'].tolist() for detail in self.output_details],
            "total_params_estimate": "unknown for TFLite"
        }

        print(f"   æ¨¡å‹æ–‡ä»¶å¤§å°: {model_stats['file_size_mb']:.2f} MB")
        print(f"   è¾“å…¥å½¢çŠ¶: {model_stats['input_shapes']}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {model_stats['output_shapes']}")

        return model_stats

    def generate_report(self, performance_stats, consistency_stats, model_stats):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        print(f"\\nğŸ“‹ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š...")

        report = {
            "model_info": {
                "tflite_file": str(self.tflite_path),
                "file_size_mb": model_stats['file_size_mb'],
                "input_shapes": model_stats['input_shapes'],
                "output_shapes": model_stats['output_shapes']
            },
            "performance": performance_stats,
            "consistency": consistency_stats,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "test_summary": {
                "model_ready_for_mobile": True,
                "inference_time_acceptable": performance_stats['avg_inference_time_ms'] < 50,
                "model_size_acceptable": model_stats['file_size_mb'] < 10,
                "output_consistent": consistency_stats['max_deviation'] < 1e-5
            }
        }

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.tflite_path.parent / "performance_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)

        print(f"ğŸ“ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª ç®€åŒ–ç‰ˆ TensorFlow Lite æ€§èƒ½æµ‹è¯•å·¥å…·")
    print("=" * 50)

    # æŸ¥æ‰¾TFLiteæ¨¡å‹
    base_dir = Path("/home/gitlab-runner/2024_TJU_Data_Mining-Analysis")
    tflite_paths = list((base_dir / "mobile_deployment" / "mobile_deployment" / "src" / "output").glob("*.tflite"))
    if not tflite_paths:
        print("âŒ æœªæ‰¾åˆ°TFLiteæ¨¡å‹æ–‡ä»¶")
        return 1

    tflite_path = tflite_paths[0]
    print(f"ğŸ” æ‰¾åˆ°TFLiteæ¨¡å‹: {tflite_path}")

    try:
        # åˆ›å»ºæµ‹è¯•å™¨
        tester = SimpleTFLiteTester(tflite_path)

        # åŠ è½½æ¨¡å‹
        tester.load_model()

        # è·å–æ¨¡å‹ä¿¡æ¯
        model_stats = tester.get_model_info()

        # æ€§èƒ½æµ‹è¯•
        performance_stats = tester.test_basic_performance()

        # ä¸€è‡´æ€§æµ‹è¯•
        consistency_stats = tester.test_accuracy_consistency()

        # ç”ŸæˆæŠ¥å‘Š
        report = tester.generate_report(performance_stats, consistency_stats, model_stats)

        print(f"\\nğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆ!")

        # æ€»ç»“å…³é”®æŒ‡æ ‡
        print(f"\\nğŸ“Š å…³é”®æ€§èƒ½æŒ‡æ ‡:")
        print(f"   âœ… æ¨¡å‹å¤§å°: {model_stats['file_size_mb']:.2f} MB")
        print(f"   âœ… æ¨ç†æ—¶é—´: {performance_stats['avg_inference_time_ms']:.2f} ms")
        print(f"   âœ… ååé‡: {performance_stats['throughput_qps']:.0f} QPS")
        print(f"   âœ… è¾“å‡ºä¸€è‡´æ€§: {consistency_stats['max_deviation']:.8f}")

        # ç§»åŠ¨ç«¯å°±ç»ªè¯„ä¼°
        mobile_ready = (
            model_stats['file_size_mb'] < 10 and
            performance_stats['avg_inference_time_ms'] < 50 and
            consistency_stats['max_deviation'] < 1e-5
        )

        if mobile_ready:
            print(f"   ğŸš€ æ¨¡å‹å·²å‡†å¤‡å¥½ç”¨äºç§»åŠ¨ç«¯éƒ¨ç½²!")
        else:
            print(f"   âš ï¸  æ¨¡å‹å¯èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–æ‰èƒ½ç”¨äºç§»åŠ¨ç«¯")

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 1

    return 0

if __name__ == "__main__":
    exit(main())